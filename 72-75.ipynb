{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioYgJTSpjcR9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/red_data_no_webp.zip\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def list_file_extensions(directory):\n",
        "    # Store unique file extensions\n",
        "    extensions = set()\n",
        "\n",
        "    # Walk through the directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            # Get the file extension and add to the set (ignoring empty extensions)\n",
        "            ext = os.path.splitext(file)[1]\n",
        "            if ext:  # Only add extensions that are not empty\n",
        "                extensions.add(ext.lower())\n",
        "\n",
        "    # Return sorted list of unique extensions\n",
        "    return sorted(extensions)\n",
        "\n",
        "# Example usage:\n",
        "directory_path = input(\"Enter the directory path: \")\n",
        "extensions = list_file_extensions('/content/red_data/img/')\n",
        "\n",
        "print(\"Unique file extensions in the directory:\")\n",
        "for ext in extensions:\n",
        "    print(ext)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X09AuXQvcOh",
        "outputId": "f3f3ff95-388f-4594-90ad-55be21d8e70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the directory path: /content/red_data/img\n",
            "Unique file extensions in the directory:\n",
            ".jpeg\n",
            ".jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "extracted_files = os.listdir('/content/red_data/img/')\n",
        "print(extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK7ARKrBNApM",
        "outputId": "b6a1d2d5-31e5-4b5e-f192-c0fecd5d5503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Metal', 'Plastic-Regular', 'Glass', 'Paperboard', 'Plastic-Polystyrene']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS-23JvPbQL-",
        "outputId": "dfe49a27-6777-4a08-9c32-36fefbb76b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.17.1\n",
            "Found 7340 files belonging to 5 classes.\n",
            "Using 6239 files for training.\n",
            "Found 7340 files belonging to 5 classes.\n",
            "Using 1101 files for validation.\n",
            "['Glass', 'Metal', 'Paperboard', 'Plastic-Polystyrene', 'Plastic-Regular']\n",
            "good extensions:\n",
            "329\n",
            "(8, 180, 180, 3)\n",
            "(8,)\n",
            "Epoch 1/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - accuracy: 0.3159 - loss: 2.0248 - val_accuracy: 0.2761 - val_loss: 2.3798 - learning_rate: 0.0010\n",
            "Epoch 2/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.3867 - loss: 1.5806 - val_accuracy: 0.2234 - val_loss: 2.5834 - learning_rate: 0.0010\n",
            "Epoch 3/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.4378 - loss: 1.4006 - val_accuracy: 0.3143 - val_loss: 1.9299 - learning_rate: 0.0010\n",
            "Epoch 4/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.4610 - loss: 1.3168 - val_accuracy: 0.5350 - val_loss: 1.1521 - learning_rate: 0.0010\n",
            "Epoch 5/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.4964 - loss: 1.2715 - val_accuracy: 0.5731 - val_loss: 1.0895 - learning_rate: 0.0010\n",
            "Epoch 6/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5011 - loss: 1.2428 - val_accuracy: 0.5795 - val_loss: 1.0761 - learning_rate: 0.0010\n",
            "Epoch 7/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5140 - loss: 1.2042 - val_accuracy: 0.4968 - val_loss: 1.2425 - learning_rate: 0.0010\n",
            "Epoch 8/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5399 - loss: 1.1664 - val_accuracy: 0.5404 - val_loss: 1.2403 - learning_rate: 0.0010\n",
            "Epoch 9/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5547 - loss: 1.1299 - val_accuracy: 0.3651 - val_loss: 1.9095 - learning_rate: 0.0010\n",
            "Epoch 10/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5409 - loss: 1.1446 - val_accuracy: 0.4678 - val_loss: 1.8869 - learning_rate: 0.0010\n",
            "Epoch 11/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5641 - loss: 1.0964 - val_accuracy: 0.5059 - val_loss: 1.3948 - learning_rate: 0.0010\n",
            "Epoch 12/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.5895 - loss: 1.0264 - val_accuracy: 0.6739 - val_loss: 0.8189 - learning_rate: 2.0000e-04\n",
            "Epoch 13/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6305 - loss: 0.9463 - val_accuracy: 0.6149 - val_loss: 0.9982 - learning_rate: 2.0000e-04\n",
            "Epoch 14/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6474 - loss: 0.9171 - val_accuracy: 0.6667 - val_loss: 0.8868 - learning_rate: 2.0000e-04\n",
            "Epoch 15/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6541 - loss: 0.9031 - val_accuracy: 0.6376 - val_loss: 1.0082 - learning_rate: 2.0000e-04\n",
            "Epoch 16/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.6533 - loss: 0.8767 - val_accuracy: 0.6612 - val_loss: 0.9037 - learning_rate: 2.0000e-04\n",
            "Epoch 17/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6668 - loss: 0.8529 - val_accuracy: 0.6412 - val_loss: 0.9616 - learning_rate: 2.0000e-04\n",
            "Epoch 18/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.6847 - loss: 0.8373 - val_accuracy: 0.7357 - val_loss: 0.7652 - learning_rate: 4.0000e-05\n",
            "Epoch 19/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6814 - loss: 0.8260 - val_accuracy: 0.7284 - val_loss: 0.7704 - learning_rate: 4.0000e-05\n",
            "Epoch 20/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6927 - loss: 0.8186 - val_accuracy: 0.7411 - val_loss: 0.7596 - learning_rate: 4.0000e-05\n",
            "Epoch 21/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6870 - loss: 0.8165 - val_accuracy: 0.7275 - val_loss: 0.7573 - learning_rate: 4.0000e-05\n",
            "Epoch 22/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6947 - loss: 0.8133 - val_accuracy: 0.7375 - val_loss: 0.7609 - learning_rate: 4.0000e-05\n",
            "Epoch 23/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.7031 - loss: 0.8033 - val_accuracy: 0.7421 - val_loss: 0.7407 - learning_rate: 4.0000e-05\n",
            "Epoch 24/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6939 - loss: 0.8026 - val_accuracy: 0.7411 - val_loss: 0.7309 - learning_rate: 4.0000e-05\n",
            "Epoch 25/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.6993 - loss: 0.7875 - val_accuracy: 0.7384 - val_loss: 0.7482 - learning_rate: 4.0000e-05\n",
            "Epoch 26/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6990 - loss: 0.7945 - val_accuracy: 0.7330 - val_loss: 0.7671 - learning_rate: 4.0000e-05\n",
            "Epoch 27/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6996 - loss: 0.7910 - val_accuracy: 0.7375 - val_loss: 0.7341 - learning_rate: 4.0000e-05\n",
            "Epoch 28/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7042 - loss: 0.7881 - val_accuracy: 0.7421 - val_loss: 0.7358 - learning_rate: 4.0000e-05\n",
            "Epoch 29/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.6978 - loss: 0.7959 - val_accuracy: 0.7484 - val_loss: 0.7115 - learning_rate: 4.0000e-05\n",
            "Epoch 30/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7163 - loss: 0.7638 - val_accuracy: 0.7312 - val_loss: 0.7688 - learning_rate: 4.0000e-05\n",
            "Epoch 31/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7082 - loss: 0.7758 - val_accuracy: 0.7457 - val_loss: 0.7173 - learning_rate: 4.0000e-05\n",
            "Epoch 32/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7018 - loss: 0.7847 - val_accuracy: 0.7330 - val_loss: 0.7490 - learning_rate: 4.0000e-05\n",
            "Epoch 33/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7112 - loss: 0.7711 - val_accuracy: 0.7402 - val_loss: 0.7235 - learning_rate: 4.0000e-05\n",
            "Epoch 34/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7059 - loss: 0.7655 - val_accuracy: 0.7448 - val_loss: 0.7055 - learning_rate: 4.0000e-05\n",
            "Epoch 35/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7099 - loss: 0.7684 - val_accuracy: 0.7457 - val_loss: 0.7337 - learning_rate: 4.0000e-05\n",
            "Epoch 36/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7184 - loss: 0.7582 - val_accuracy: 0.7284 - val_loss: 0.7687 - learning_rate: 4.0000e-05\n",
            "Epoch 37/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7249 - loss: 0.7522 - val_accuracy: 0.7402 - val_loss: 0.7353 - learning_rate: 4.0000e-05\n",
            "Epoch 38/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7221 - loss: 0.7464 - val_accuracy: 0.7484 - val_loss: 0.7269 - learning_rate: 4.0000e-05\n",
            "Epoch 39/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7144 - loss: 0.7541 - val_accuracy: 0.7448 - val_loss: 0.7509 - learning_rate: 4.0000e-05\n",
            "Epoch 40/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7154 - loss: 0.7459 - val_accuracy: 0.7502 - val_loss: 0.7155 - learning_rate: 1.0000e-05\n",
            "Epoch 41/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7240 - loss: 0.7377 - val_accuracy: 0.7566 - val_loss: 0.6981 - learning_rate: 1.0000e-05\n",
            "Epoch 42/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7195 - loss: 0.7375 - val_accuracy: 0.7511 - val_loss: 0.7046 - learning_rate: 1.0000e-05\n",
            "Epoch 43/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7170 - loss: 0.7496 - val_accuracy: 0.7548 - val_loss: 0.7026 - learning_rate: 1.0000e-05\n",
            "Epoch 44/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7316 - loss: 0.7392 - val_accuracy: 0.7548 - val_loss: 0.6918 - learning_rate: 1.0000e-05\n",
            "Epoch 45/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7174 - loss: 0.7468 - val_accuracy: 0.7530 - val_loss: 0.7063 - learning_rate: 1.0000e-05\n",
            "Epoch 46/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7273 - loss: 0.7326 - val_accuracy: 0.7457 - val_loss: 0.7187 - learning_rate: 1.0000e-05\n",
            "Epoch 47/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7242 - loss: 0.7380 - val_accuracy: 0.7557 - val_loss: 0.6971 - learning_rate: 1.0000e-05\n",
            "Epoch 48/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7171 - loss: 0.7505 - val_accuracy: 0.7548 - val_loss: 0.6968 - learning_rate: 1.0000e-05\n",
            "Epoch 49/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7238 - loss: 0.7294 - val_accuracy: 0.7548 - val_loss: 0.6933 - learning_rate: 1.0000e-05\n",
            "Epoch 50/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7308 - loss: 0.7256 - val_accuracy: 0.7548 - val_loss: 0.7097 - learning_rate: 1.0000e-05\n",
            "Epoch 51/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7224 - loss: 0.7326 - val_accuracy: 0.7539 - val_loss: 0.7014 - learning_rate: 1.0000e-05\n",
            "Epoch 52/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7173 - loss: 0.7334 - val_accuracy: 0.7520 - val_loss: 0.6947 - learning_rate: 1.0000e-05\n",
            "Epoch 53/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.7321 - loss: 0.7211 - val_accuracy: 0.7575 - val_loss: 0.6972 - learning_rate: 1.0000e-05\n",
            "Epoch 54/150\n",
            "\u001b[1m780/780\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.7283 - loss: 0.7263 - val_accuracy: 0.7539 - val_loss: 0.7117 - learning_rate: 1.0000e-05\n",
            "done training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "  import tensorflow as tf\n",
        "  import numpy as np\n",
        "  import os\n",
        "  import PIL\n",
        "  import PIL.Image\n",
        "  import tensorflow as tf\n",
        "  import tensorflow_datasets as tdfs\n",
        "  import keras\n",
        "\n",
        "  from keras import datasets\n",
        "  from keras import layers\n",
        "  from keras import activations\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "  print(\"Tensorflow version\", tf.__version__)\n",
        "\n",
        "  import tensorflow as tf\n",
        "  import pathlib\n",
        "  from PIL import Image\n",
        "\n",
        "  # Image dimensions\n",
        "  img_height = 180\n",
        "  img_width = 180\n",
        "  batch_size = 8\n",
        "\n",
        "  # Path to your image directory\n",
        "  str_path = '/content/red_data/img/'\n",
        "  data_dir = pathlib.Path(str_path)\n",
        "\n",
        "  train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "      data_dir,\n",
        "      validation_split=0.15,\n",
        "      subset=\"training\",\n",
        "      seed=123,\n",
        "      image_size=(img_height, img_width),\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "      data_dir,\n",
        "      validation_split=0.15,\n",
        "      subset=\"validation\",\n",
        "      seed=123,\n",
        "      image_size=(img_height, img_width),\n",
        "      batch_size=batch_size\n",
        "  )\n",
        "\n",
        "  # Now the images should be properly decoded and ready for use in training\n",
        "\n",
        "  class_names = train_ds.class_names\n",
        "  print(class_names)\n",
        "  from pathlib import Path\n",
        "  import imghdr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  resize_and_rescale = tf.keras.Sequential([\n",
        "    tf.keras.layers.Resizing(img_height, img_width),\n",
        "    tf.keras.layers.Rescaling(1./255)\n",
        "  ])\n",
        "\n",
        "  data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomTranslation(height_factor=0.2 ,width_factor=0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    #tf.keras.layers.RandomContrast(0.2)\n",
        "  ])\n",
        "\n",
        "  normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "  train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "  num_classes = 5\n",
        "\n",
        "\n",
        "\n",
        "  import tensorflow as tf\n",
        "  from tensorflow.keras.regularizers import l1_l2\n",
        "  from tensorflow.keras.regularizers import l2\n",
        "  import tensorflow as tf\n",
        "\n",
        "  num_classes = 5\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(240, 240, 3)),\n",
        "        tf.keras.layers.Rescaling(1./255),\n",
        "        data_augmentation,\n",
        "\n",
        "\n",
        "        # Initial Convolutional Layer\n",
        "        tf.keras.layers.Conv2D(32, 7, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        # Adding Depth with Convolutional Layers\n",
        "        tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(padding='same'),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(padding='same'),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "        # Adding more depth and regularization\n",
        "        tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(padding='same'),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "\n",
        "        tf.keras.layers.Conv2D(512, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(padding='same'),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "        # Flatten the output and add fully connected layers\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "\n",
        "\n",
        "  # Compile the model and define loss\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Callbacks\n",
        "  callbacks = [\n",
        "      tf.keras.callbacks.ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss'),\n",
        "      tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "      tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "  ]\n",
        "\n",
        "  # Fit the model with class weights\n",
        "  model.fit(\n",
        "      train_ds,\n",
        "      validation_data=val_ds,\n",
        "      epochs=150,\n",
        "      callbacks=callbacks,\n",
        "      class_weight=class_weights_dict\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "\n",
        "\n",
        "\n",
        "  print(\"done training\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.save('GPTmodel_rose.keras') # also can work ~ model.save('rose_model.keras')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sytDDiWabXbG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qymi9Gwo3mgf"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
